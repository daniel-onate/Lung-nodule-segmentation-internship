{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc09c6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unet2dmodel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909e9d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch shape: torch.Size([32, 1, 64, 64])\n",
      "Mask batch shape: torch.Size([32, 1, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "# ============================\n",
    "# 1. Custom Dataset definition\n",
    "# ============================\n",
    "class TumorDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.image_files = sorted(os.listdir(image_dir))\n",
    "        self.mask_files = sorted(os.listdir(mask_dir))\n",
    "\n",
    "        assert len(self.image_files) == len(self.mask_files), \"Mismatch between image and mask counts.\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load the numpy arrays\n",
    "        img_path = os.path.join(self.image_dir, self.image_files[idx])\n",
    "        mask_path = os.path.join(self.mask_dir, self.mask_files[idx])\n",
    "\n",
    "        image = np.load(img_path).astype(np.float32)\n",
    "        mask = np.load(mask_path).astype(np.float32)\n",
    "\n",
    "        # Normalize image and mask between 0 and 1\n",
    "        image = (image - image.min()) / (image.max() - image.min() + 1e-8)\n",
    "        mask = (mask - mask.min()) / (mask.max() - mask.min() + 1e-8)\n",
    "\n",
    "        # Add channel dimension (1, H, W)\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        mask = np.expand_dims(mask, axis=0)\n",
    "\n",
    "        # Convert to torch tensors\n",
    "        image = torch.from_numpy(image)\n",
    "        mask = torch.from_numpy(mask)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "\n",
    "# ============================\n",
    "# 2. Create dataset\n",
    "# ============================\n",
    "image_dir = \"/Users/daniel/Documents/CSAI/Internship/CODE/data/LUNA16/images\"\n",
    "mask_dir = \"/Users/daniel/Documents/CSAI/Internship/CODE/data/LUNA16/labels\"\n",
    "dataset = TumorDataset(image_dir, mask_dir)\n",
    "\n",
    "# ============================\n",
    "# 3. Split into train/val/test\n",
    "# ============================\n",
    "total_size = len(dataset)\n",
    "train_size = int(0.7 * total_size)\n",
    "val_size = int(0.15 * total_size)\n",
    "test_size = total_size - train_size - val_size\n",
    "\n",
    "train_set, val_set, test_set = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# ============================\n",
    "# 4. Create DataLoaders\n",
    "# ============================\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# ============================\n",
    "# 5. Example check\n",
    "# ============================\n",
    "images, masks = next(iter(train_loader))\n",
    "print(\"Image batch shape:\", images.shape)  # [32, 1, 64, 64]\n",
    "print(\"Mask batch shape:\", masks.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "90daa42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1e-6):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        preds = torch.sigmoid(preds)  # for logits output\n",
    "        preds = preds.view(preds.size(0), -1)\n",
    "        targets = targets.view(targets.size(0), -1)\n",
    "\n",
    "        intersection = (preds * targets).sum(dim=1)\n",
    "        dice = (2. * intersection + self.smooth) / (preds.sum(dim=1) + targets.sum(dim=1) + self.smooth)\n",
    "        loss = 1 - dice.mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2255070f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(Conv => BN => ReLU) * 2\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.enc1 = DoubleConv(in_channels, 64)\n",
    "        self.enc2 = DoubleConv(64, 128)\n",
    "        self.enc3 = DoubleConv(128, 256)\n",
    "        self.enc4 = DoubleConv(256, 512)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = DoubleConv(512, 1024)\n",
    "\n",
    "        # Decoder\n",
    "        self.up1 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.dec1 = DoubleConv(1024, 512)\n",
    "        self.up2 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.dec2 = DoubleConv(512, 256)\n",
    "        self.up3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec3 = DoubleConv(256, 128)\n",
    "        self.up4 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec4 = DoubleConv(128, 64)\n",
    "\n",
    "        # Output\n",
    "        self.out_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1 = self.enc1(x)\n",
    "        x2 = self.pool(x1)\n",
    "        x3 = self.enc2(x2)\n",
    "        x4 = self.pool(x3)\n",
    "        x5 = self.enc3(x4)\n",
    "        x6 = self.pool(x5)\n",
    "        x7 = self.enc4(x6)\n",
    "        x8 = self.pool(x7)\n",
    "\n",
    "        # Bottleneck\n",
    "        x9 = self.bottleneck(x8)\n",
    "\n",
    "        # Decoder\n",
    "        x = self.up1(x9)\n",
    "        x = self.dec1(torch.cat([x, x7], dim=1))\n",
    "        x = self.up2(x)\n",
    "        x = self.dec2(torch.cat([x, x5], dim=1))\n",
    "        x = self.up3(x)\n",
    "        x = self.dec3(torch.cat([x, x3], dim=1))\n",
    "        x = self.up4(x)\n",
    "        x = self.dec4(torch.cat([x, x1], dim=1))\n",
    "\n",
    "        return self.out_conv(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1a2d35ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50]  Train Loss: 0.8288  Val Loss: 0.8627\n",
      "Epoch [2/50]  Train Loss: 0.7773  Val Loss: 0.8620\n",
      "Epoch [3/50]  Train Loss: 0.7391  Val Loss: 0.8617\n",
      "Epoch [4/50]  Train Loss: 0.7126  Val Loss: 0.8614\n",
      "Epoch [5/50]  Train Loss: 0.6938  Val Loss: 0.8606\n",
      "Epoch [6/50]  Train Loss: 0.6772  Val Loss: 0.8591\n",
      "Epoch [7/50]  Train Loss: 0.6642  Val Loss: 0.8532\n",
      "Epoch [8/50]  Train Loss: 0.6532  Val Loss: 0.8240\n",
      "Epoch [9/50]  Train Loss: 0.6441  Val Loss: 0.7863\n",
      "Epoch [10/50]  Train Loss: 0.6365  Val Loss: 0.7610\n",
      "Epoch [11/50]  Train Loss: 0.6304  Val Loss: 0.7498\n",
      "Epoch [12/50]  Train Loss: 0.6247  Val Loss: 0.7237\n",
      "Epoch [13/50]  Train Loss: 0.6200  Val Loss: 0.7057\n",
      "Epoch [14/50]  Train Loss: 0.6158  Val Loss: 0.6896\n",
      "Epoch [15/50]  Train Loss: 0.6126  Val Loss: 0.6670\n",
      "Epoch [16/50]  Train Loss: 0.6096  Val Loss: 0.6528\n",
      "Epoch [17/50]  Train Loss: 0.6074  Val Loss: 0.6471\n",
      "Epoch [18/50]  Train Loss: 0.6049  Val Loss: 0.6292\n",
      "Epoch [19/50]  Train Loss: 0.6025  Val Loss: 0.6260\n",
      "Epoch [20/50]  Train Loss: 0.5999  Val Loss: 0.6255\n",
      "Epoch [21/50]  Train Loss: 0.5978  Val Loss: 0.6222\n",
      "Epoch [22/50]  Train Loss: 0.5956  Val Loss: 0.6186\n",
      "Epoch [23/50]  Train Loss: 0.5942  Val Loss: 0.6168\n",
      "Epoch [24/50]  Train Loss: 0.5923  Val Loss: 0.6202\n",
      "Epoch [25/50]  Train Loss: 0.5897  Val Loss: 0.6144\n",
      "Epoch [26/50]  Train Loss: 0.5883  Val Loss: 0.6138\n",
      "Epoch [27/50]  Train Loss: 0.5861  Val Loss: 0.6121\n",
      "Epoch [28/50]  Train Loss: 0.5839  Val Loss: 0.6081\n",
      "Epoch [29/50]  Train Loss: 0.5823  Val Loss: 0.6049\n",
      "Epoch [30/50]  Train Loss: 0.5800  Val Loss: 0.6025\n",
      "Epoch [31/50]  Train Loss: 0.5781  Val Loss: 0.6018\n",
      "Epoch [32/50]  Train Loss: 0.5769  Val Loss: 0.6041\n",
      "Epoch [33/50]  Train Loss: 0.5753  Val Loss: 0.6083\n",
      "Epoch [34/50]  Train Loss: 0.5732  Val Loss: 0.6064\n",
      "Epoch [35/50]  Train Loss: 0.5708  Val Loss: 0.5895\n",
      "Epoch [36/50]  Train Loss: 0.5685  Val Loss: 0.5855\n",
      "Epoch [37/50]  Train Loss: 0.5666  Val Loss: 0.5772\n",
      "Epoch [38/50]  Train Loss: 0.5649  Val Loss: 0.5802\n",
      "Epoch [39/50]  Train Loss: 0.5618  Val Loss: 0.5776\n",
      "Epoch [40/50]  Train Loss: 0.5608  Val Loss: 0.5632\n",
      "Epoch [41/50]  Train Loss: 0.5575  Val Loss: 0.5503\n",
      "Epoch [42/50]  Train Loss: 0.5567  Val Loss: 0.5547\n",
      "Epoch [43/50]  Train Loss: 0.5542  Val Loss: 0.5812\n",
      "Epoch [44/50]  Train Loss: 0.5540  Val Loss: 0.5634\n",
      "Epoch [45/50]  Train Loss: 0.5509  Val Loss: 0.5573\n",
      "Epoch [46/50]  Train Loss: 0.5499  Val Loss: 0.5691\n",
      "Epoch [47/50]  Train Loss: 0.5457  Val Loss: 0.6307\n",
      "Epoch [48/50]  Train Loss: 0.5438  Val Loss: 0.6802\n",
      "Epoch [49/50]  Train Loss: 0.5416  Val Loss: 0.6973\n",
      "Epoch [50/50]  Train Loss: 0.5424  Val Loss: 0.6948\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Initialize model, loss, optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet(in_channels=1, out_channels=1).to(device)\n",
    "criterion = DiceLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for images, masks in train_loader:\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, masks in val_loader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]  Train Loss: {train_loss:.4f}  Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    if train_loss < 0.2:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9b477031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Dice coefficient on test set: 0.1342\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def dice_coeff(preds, targets, smooth=1e-6):\n",
    "    \"\"\"Computes Dice coefficient (same idea as Dice loss, but as a score).\"\"\"\n",
    "    preds = torch.sigmoid(preds)  # convert logits to probabilities\n",
    "    preds = (preds > 0.5).float()  # threshold to binary mask\n",
    "\n",
    "    preds = preds.view(preds.size(0), -1)\n",
    "    targets = targets.view(targets.size(0), -1)\n",
    "\n",
    "    intersection = (preds * targets).sum(dim=1)\n",
    "    dice = (2. * intersection + smooth) / (preds.sum(dim=1) + targets.sum(dim=1) + smooth)\n",
    "    return dice.mean().item()\n",
    "\n",
    "\n",
    "model.eval()\n",
    "test_dice = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, masks in test_loader:\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "        outputs = model(images)\n",
    "        test_dice += dice_coeff(outputs, masks)\n",
    "\n",
    "test_dice /= len(test_loader)\n",
    "print(f\"Mean Dice coefficient on test set: {test_dice:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1892abb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''class UNet2DModel(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1, init_features=32):\n",
    "        super(UNet2DModel, self).__init__()\n",
    "        features = init_features\n",
    "        self.encoder1 = UNet2DModel._block(in_channels, features, name=\"enc1\")\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder2 = UNet2DModel._block(features, features * 2, name=\"enc2\")\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder3 = UNet2DModel._block(features * 2, features * 4, name=\"enc3\")\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder4 = UNet2DModel._block(features * 4, features * 8, name=\"enc4\")\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.bottleneck = UNet2DModel._block(features * 8, features * 16, name=\"bottleneck\")\n",
    "\n",
    "        self.upconv4 = nn.ConvTranspose2d(\n",
    "            features * 16, features * 8, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder4 = UNet2DModel._block((features * 8) * 2, features * 8, name=\"dec4\")\n",
    "        self.upconv3 = nn.ConvTranspose2d(\n",
    "            features * 8, features * 4, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder3 = UNet2DModel._block((features * 4) * 2, features * 4, name=\"dec3\")\n",
    "        self.upconv2 = nn.ConvTranspose2d(\n",
    "            features * 4, features * 2, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder2 = UNet2DModel._block((features * 2) * 2, features * 2, name=\"dec2\")\n",
    "        self.upconv1 = nn.ConvTranspose2d(\n",
    "            features * 2, features, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder1 = UNet2DModel._block(features * 2, features, name=\"dec1\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(self.pool1(enc1))\n",
    "        enc3 = self.encoder3(self.pool2(enc2))\n",
    "        enc4 = self.encoder4(self.pool3(enc3))\n",
    "\n",
    "        bottleneck = self.bottleneck(self.pool4(enc4))\n",
    "\n",
    "        dec4 = self.upconv4(bottleneck)\n",
    "        dec4 = torch.cat((dec4, enc4), dim=1)\n",
    "        dec4 = self.decoder4(dec4)\n",
    "        dec3 = self.upconv3(dec4)\n",
    "        dec3 = torch.cat((dec3, enc3), dim=1)\n",
    "        dec3 = self.decoder3(dec3)\n",
    "        dec2 = self.upconv2(dec3)\n",
    "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
    "        dec2 = self.decoder2(dec2)\n",
    "        dec1 = self.upconv1(dec2)\n",
    "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
    "        dec1 = self.decoder1(dec1)\n",
    "\n",
    "        return torch.sigmoid(dec1)'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
